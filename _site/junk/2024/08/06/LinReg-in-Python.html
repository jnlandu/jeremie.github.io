<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Linear Regression in Python | Jérémie N. Mabiala</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Linear Regression in Python" />
<meta property="og:locale" content="en" />
<meta name="description" content="Linear Regression in Python" />
<meta property="og:description" content="Linear Regression in Python" />
<link rel="canonical" href="http://localhost:4000/junk/2024/08/06/LinReg-in-Python.html" />
<meta property="og:url" content="http://localhost:4000/junk/2024/08/06/LinReg-in-Python.html" />
<meta property="og:site_name" content="Jérémie N. Mabiala" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-08-06T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Linear Regression in Python" />
<meta name="twitter:site" content="@ngzhio" />
<meta name="google-site-verification" content="u4WXQl0Eu66rsQo2kRdCNx" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-08-06T00:00:00+00:00","datePublished":"2024-08-06T00:00:00+00:00","description":"Linear Regression in Python","headline":"Linear Regression in Python","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/junk/2024/08/06/LinReg-in-Python.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/logo.png"}},"url":"http://localhost:4000/junk/2024/08/06/LinReg-in-Python.html"}</script>
<!-- End Jekyll SEO tag -->


<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Jérémie N. Mabiala" />





<!-- Google Fonts -->
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open%20Sans|Roboto|Roboto%20Slab|Inconsolata|Dancing%20Script|Noto%20Sans%20SC|Noto%20Sans%20TC|Noto%20Serif%20SC|Noto%20Serif%20TC|Ma%20Shan%20Zheng">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/skin.css">

<!-- Begin selecting skin -->

  <script>
    const hour = (new Date()).getHours();
    let filename = "";
    if (hour >= 5 && hour < 7) {
      filename = "/assets/css/skin-sunrise.css";
    } else if (hour >= 7 && hour < 17) {
      filename = "/assets/css/skin-daylight.css";
    } else if (hour >= 17 && hour < 19) {
      filename = "/assets/css/skin-sunset.css";
    } else {
      filename = "/assets/css/skin-midnight.css";
    }
    const elem = document.createElement("link");
    elem.setAttribute("rel", "stylesheet");
    elem.setAttribute("type", "text/css");
    elem.setAttribute("href", filename);
    document.getElementsByTagName("head")[0].appendChild(elem);
  </script>

<!-- End selecting skin -->

<script async src="https://use.fontawesome.com/releases/v5.0.12/js/all.js"></script>




  </head>

  <body>
    <div class="site-container">
      <header class="site-header">
        <div class="wrapper">
  <script>
    function clickSidebarButton() {
      const elem = document.getElementById("site-sidebar")
      if (elem.style.display == "none" || elem.style.display == "") {
        elem.style.display = "block";
      } else {
        elem.style.display = "none";
      }
    }
  </script>
  <a class="site-sidebar-button" onclick="clickSidebarButton()"><i class="far fa-user"></i>
  </a>

  <a class="site-title" rel="author" href="/">Jérémie N. Mabiala</a>

  
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger" title="nav-trigger">
        <span class="menu-icon">
          <svg viewBox="0 0 18 15" width="18px" height="15px">
            <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
          </svg>
        </span>
      </label>

      <ul class="trigger">
              <li><a class="" href="/about/">About</a></li>
            
              <li><a class="" href="/years/">Years</a></li>
            
              <li><a class="" href="/categories/">Categories</a></li>
            
              <li><a class="" href="/tags/">Tags</a></li>
            
              <li class="dropdown" href="#">
                <a href="javascript:void(0)" class="dropbtn">More</a>
                <div class="dropdown-content">
                    <a class="" href="/faq/">FAQ</a>
                    <a class="" href="/docs/">Docs</a>
                </div>
              </li>
            </ul>
    </nav>
  
</div>

      </header>
      
      <div class="site-body wrapper">
        <aside class="site-sidebar" id="site-sidebar">
          
            <h3 class="toc-title">Table of Contents</h3>
<nav class="toc-nav">
  <ul class="toc">
  <li><a href="#table-of-contents">Table of Contents</a></li>
  <li><a href="#introduction-to-linear-regression">Introduction to Linear Regression</a></li>
  <li><a href="#mathematical-background">Mathematical Background</a></li>
  <li><a href="#implementing-linear-regression-from-scratch">Implementing Linear Regression from Scratch</a>
    <ul>
      <li><a href="#step-1-compute-the-cost-function">Step 1: Compute the Cost Function</a></li>
      <li><a href="#step-2-gradient-descent">Step 2: Gradient Descent</a></li>
      <li><a href="#step-3-training-the-model">Step 3: Training the Model</a></li>
      <li><a href="#step-4-plot-the-cost-function">Step 4: Plot the Cost Function</a></li>
      <li><a href="#step-5-predictions">Step 5: Predictions</a></li>
    </ul>
  </li>
  <li><a href="#linear-regression-using-scikit-learn">Linear Regression Using scikit-learn</a></li>
  <li><a href="#evaluation-metrics">Evaluation Metrics</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

</nav>

          
        </aside>
        <main class="site-main" id="site-main" aria-label="Content" tabindex="1">
          <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">

    <h1 class="post-title p-name" itemprop="name headline">Linear Regression in Python</h1>
    <p class="post-meta"><time class="dt-published" datetime="2024-08-06T00:00:00+00:00" itemprop="datePublished">
        Aug 6, 2024
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Jérémie N. Mabiala</span></span></p>

  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="linear-regression-in-python">Linear Regression in Python</h1>

<p>Linear Regression is a simple yet powerful technique used for predicting a quantitative response. In this tutorial, we will implement Linear Regression from scratch and also using the <code class="language-plaintext highlighter-rouge">scikit-learn</code> library in Python.</p>

<h2 id="table-of-contents">Table of Contents</h2>
<ol>
  <li><a href="#introduction-to-linear-regression">Introduction to Linear Regression</a></li>
  <li><a href="#mathematical-background">Mathematical Background</a></li>
  <li><a href="#implementing-linear-regression-from-scratch">Implementing Linear Regression from Scratch</a></li>
  <li><a href="#linear-regression-using-scikit-learn">Linear Regression Using scikit-learn</a></li>
  <li><a href="#evaluation-metrics">Evaluation Metrics</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ol>

<h2 id="introduction-to-linear-regression">Introduction to Linear Regression</h2>

<p>Linear Regression is a linear approach to modeling the relationship between a dependent variable and one or more independent variables. If we have a single independent variable, it’s called Simple Linear Regression. If there are multiple independent variables, it’s called Multiple Linear Regression.</p>

<h2 id="mathematical-background">Mathematical Background</h2>

<p>The equation for a linear model is:</p>

<p>$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_n x_n + \epsilon $</p>

<ul>
  <li>$ y $: Dependent variable</li>
  <li>$ x_i $: Independent variables</li>
  <li>$ \beta_i $: Coefficients</li>
  <li>$ \epsilon $: Error term</li>
</ul>

<h2 id="implementing-linear-regression-from-scratch">Implementing Linear Regression from Scratch</h2>

<p>Let’s start by generating some sample data and implementing Linear Regression using NumPy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Generate sample data
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Plot the sample data
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"X"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"y"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Sample Data"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="step-1-compute-the-cost-function">Step 1: Compute the Cost Function</h3>
<p>The cost function for Linear Regression is the Mean Squared Error (MSE):</p>

<p>[ J(\beta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\beta(x^{(i)}) - y^{(i)})^2 ]</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">cost</span>
</code></pre></div></div>

<h3 id="step-2-gradient-descent">Step 2: Gradient Descent</h3>
<p>Gradient Descent is used to minimize the cost function:</p>

<p>[ \beta_j := \beta_j - \alpha \frac{\partial}{\partial \beta_j} J(\beta) ]</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">iterations</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">iterations</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="n">errors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">beta</span> <span class="o">-=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">errors</span>
        <span class="n">cost_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">beta</span><span class="p">,</span> <span class="n">cost_history</span>
</code></pre></div></div>

<h3 id="step-3-training-the-model">Step 3: Training the Model</h3>
<p>Let’s normalize the feature and add a bias term to the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">]</span>  <span class="c1"># Add bias term
</span><span class="n">beta_initial</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">beta_optimal</span><span class="p">,</span> <span class="n">cost_history</span> <span class="o">=</span> <span class="n">gradient_descent</span><span class="p">(</span><span class="n">X_b</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">beta_initial</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Optimal coefficients:"</span><span class="p">,</span> <span class="n">beta_optimal</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="step-4-plot-the-cost-function">Step 4: Plot the Cost Function</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">),</span> <span class="n">cost_history</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Iterations"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Cost"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Cost Function"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="step-5-predictions">Step 5: Predictions</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictions</span> <span class="o">=</span> <span class="n">X_b</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta_optimal</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"X"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"y"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Linear Regression Fit"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="linear-regression-using-scikit-learn">Linear Regression Using scikit-learn</h2>

<p>Now, let’s use the <code class="language-plaintext highlighter-rouge">scikit-learn</code> library to perform Linear Regression.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Create and fit the model
</span><span class="n">lin_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lin_reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Print the coefficients
</span><span class="k">print</span><span class="p">(</span><span class="s">"Intercept:"</span><span class="p">,</span> <span class="n">lin_reg</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Coefficient:"</span><span class="p">,</span> <span class="n">lin_reg</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>

<span class="c1"># Predictions
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">lin_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Plot the results
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"X"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"y"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Linear Regression Fit with scikit-learn"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="evaluation-metrics">Evaluation Metrics</h2>

<p>To evaluate the performance of a Linear Regression model, we use metrics like:</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Mean Absolute Error (MAE)</strong>: $ \frac{1}{m} \sum_{i=1}^{m}</td>
          <td>y^{(i)} - \hat{y}^{(i)}</td>
          <td>$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><strong>Mean Squared Error (MSE)</strong>: $ \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2 $</li>
  <li><strong>R-squared (R²)</strong>: Proportion of variance explained by the model.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Mean Absolute Error: </span><span class="si">{</span><span class="n">mae</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Mean Squared Error: </span><span class="si">{</span><span class="n">mse</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R-squared: </span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>In this tutorial, we covered the basics of Linear Regression, implemented it from scratch, and also used the <code class="language-plaintext highlighter-rouge">scikit-learn</code> library. We also discussed how to evaluate the model using different metrics.</p>

<p>For further reading, you may refer to:</p>
<ul>
  <li><a href="https://www.statlearning.com/">Introduction to Statistical Learning</a></li>
  <li><a href="https://scikit-learn.org/stable/documentation.html">scikit-learn Documentation</a></li>
</ul>

<p>```</p>

  </div>

  <footer class="post-footer">
    
      <div class="post-meta">
        <i class="fas fa-folder"></i>
        <ul class="post-taxonomies post-categories">
          
          
            <li class="post-category">
              
              <a href="/categories/#junk">junk</a>
            </li>
          
        </ul>
      </div>
    

    
      <div class="post-meta">
        <i class="fas fa-tags"></i>
        <ul class="post-taxonomies post-tags">
          
          
            <li class="post-tag">
              
              <a href="/tags/#python">python</a>
            </li>
          
        </ul>
      </div>
    

    <nav class="post-pagination" role="navigation">
      
        <a class="post-previous" href="/junk/2024/08/05/this-post-demonstrates-post-content-styles.html">
          <h4 class="post-pagination-label">Prev</h4>
          <span class="post-pagination-title">
            <i class="fas fa-arrow-left"></i> This post demonstrates post content styles

          </span>
        </a>
      

      
    </nav>
  </footer>

  
  
</article>

          <footer class="site-footer">
            <div class="footer-col-wrapper">

  <div class="footer-col">
    <div class="copyright">
      
      
      
      
      <p>Copyright © 2016&nbsp;-&nbsp;2024 Jeremie N. Mabiala; All rights reserved.</p>
      
    </div>
    <p>
      Powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://github.com/ngzhio/jekyll-theme-hamilton">Hamilton</a>
    </p>
  </div>

  <div class="footer-col">
    <p>A minimal and beautiful Jekyll theme best for writing and note-taking.</p>
  </div>
</div>

          </footer>
        </main>
      </div>
    </div>
  </body>

</html>
